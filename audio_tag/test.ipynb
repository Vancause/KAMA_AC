{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "dir1 =\"audioTagNum_development_fin_nv.pickle\"\n",
    "dir2 =\"audioTagNum_evaluation_fin_nv.pickle\"\n",
    "dir3 =\"audioTagNum_validation_fin_nv.pickle\"\n",
    "\n",
    "tags1 = pickle.load(open(dir1,'rb'))\n",
    "\n",
    "tags2 = pickle.load(open(dir2,'rb'))\n",
    "\n",
    "tags3 = pickle.load(open(dir3,'rb'))\n",
    "tags1.update(tags2)\n",
    "tags1.update(tags3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sum = torch.as_tensor([i for v,i in tags1.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sum = all_sum.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_sum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "word_list = pickle.load(open('word_list_pretrain_rules_train_new.p','rb'))\n",
    "all_words_list = pickle.load(open('/data/yzj_data/workspace/DCASE2021_task6_v2/data/pickles/words_list.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yzj_data/anaconda3/envs/torch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "glove_feat =  pickle.load(open('/data/yzj_data/workspace/DCASE2021_task6_v2/data/fasttext/fasttext_300d.p','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4367, 300])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_feat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensor = []\n",
    "for w in word_list:\n",
    "    if w not in all_words_list:\n",
    "        print(w)\n",
    "    else:\n",
    "        torch_tensor.append(glove_feat[all_words_list.index(w)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensor = torch.stack(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_weights.p', 'wb') as f:\n",
    "    pickle.dump(torch_tensor,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1477, -0.1010, -0.4215,  ..., -0.0871, -0.0876,  0.2011],\n",
       "        [ 0.1160, -0.1125,  0.0456,  ..., -0.3058, -0.0041,  0.0405],\n",
       "        [ 0.0185,  0.1381, -0.2900,  ..., -0.0183, -0.2694, -0.3867],\n",
       "        ...,\n",
       "        [-0.0688,  0.5046,  0.0790,  ..., -0.0651,  0.0357, -0.4213],\n",
       "        [ 0.4447,  0.0121, -0.0052,  ..., -0.6845, -0.2600, -0.3119],\n",
       "        [ 0.0234, -0.3068, -0.2978,  ..., -0.5157,  0.1475,  0.1882]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = pickle.load(open('audioTagName_development_fin_nv_train_new.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "background\n",
      "someone\n",
      "time\n",
      "play\n",
      "object\n",
      "make\n",
      "distance\n",
      "something\n",
      "start\n",
      "turn\n",
      "get\n",
      "follow\n",
      "come\n",
      "group\n",
      "piece\n",
      "leave\n",
      "begin\n",
      "forth\n",
      "end\n",
      "continue\n",
      "foreground\n",
      "approach\n",
      "rate\n",
      "occur\n",
      "take\n",
      "slow\n",
      "use\n",
      "lot\n",
      "place\n",
      "repeat\n",
      "work\n",
      "item\n",
      "has\n",
      "increase\n",
      "change\n",
      "set\n",
      "page\n",
      "create\n",
      "way\n",
      "have\n",
      "put\n",
      "made\n",
      "night\n",
      "other\n",
      "second\n",
      "note\n",
      "cause\n",
      "pattern\n",
      "variety\n",
      "accelerate\n",
      "overhead\n",
      "become\n",
      "top\n",
      "side\n",
      "day\n",
      "back\n",
      "interval\n",
      "path\n",
      "thing\n",
      "couple\n",
      "signal\n",
      "number\n",
      "system\n",
      "try\n",
      "kind\n",
      "somebody\n",
      "past\n",
      "effect\n",
      "frequency\n",
      "proximity\n",
      "amount\n",
      "cover\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "import pdb\n",
    "# stop_words = ['time','times','object', 'make', 'play', 'distance', 'go', 'something', 'turn', 'get', 'come', 'follow', 'use',\n",
    "#  'piece', 'have','approach', 'rate', 'take', 'begin', 'end', 'forth', 'slow', 'continue', 'lot', 'work', 'place',\n",
    "#  'create', 'night', 'set', 'increase', 'page', 'others', 'put', 'item', 'way', 'variety', 'passing', 'do', 'repeat',\n",
    "#  'occur', 'leave', 'try', 'speaks', 'side', 'past', 'accelerate', 'overhead', 'path', 'thing', 'become',\n",
    "#  'kind', 'pattern', 'day', 'cause', 'frequency', 'couple', 'second', 'closing', 'note', 'interval',\n",
    "#  'vary', 'proximity', 'number', 'cover', 'system', 'effect','start','go','someone',\n",
    "#  'back','become','come','do',\"amount\",'has','other','top','background','person','people','group','made','foreground','somebody']\n",
    "\n",
    "\n",
    "stop_words = ['time','times','object', 'make', 'play', 'distance', 'go', 'something', 'turn', 'get', 'come', 'follow', 'use',\n",
    " 'piece', 'have','approach', 'rate', 'take', 'begin', 'end', 'forth', 'slow', 'continue', 'lot', 'work', 'place',\n",
    " 'create', 'night', 'set', 'increase', 'page', 'others', 'put', 'item', 'way', 'variety', 'passing', 'do', 'repeat',\n",
    " 'occur', 'leave', 'try', 'speaks', 'side', 'past', 'accelerate', 'overhead', 'path', 'thing', 'signal', 'become',\n",
    " 'kind', 'pattern', 'day', 'cause', 'frequency', 'couple', 'second', 'closing', 'note', 'interval',\n",
    " 'vary', 'proximity', 'number', 'cover', 'system', 'effect','start','go','someone',\n",
    " 'back','become','change','come','do',\"amount\",'has','other','top', 'background', 'group','made','foreground','somebody']\n",
    "\n",
    "\n",
    "def dict_add(word_freq_dict, w, f):\n",
    "    if w in word_freq_dict.keys():\n",
    "        word_freq_dict[w] += f\n",
    "    else:\n",
    "        word_freq_dict[w] = f\n",
    "    return word_freq_dict\n",
    "word_list = pickle.load(open(\"../create_dataset/data/pickles/words_list.p\",\"rb\"))\n",
    "train_csv = \"../create_dataset/data/clotho_csv_files/clotho_captions_development.csv\"\n",
    "test_csv = \"../create_dataset/data/clotho_csv_files/clotho_captions_evaluation.csv\"\n",
    "val_csv = \"../create_dataset/data/clotho_csv_files/clotho_captions_validation.csv\"\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test = pd.read_csv(test_csv)\n",
    "df_val = pd.read_csv(val_csv)\n",
    "data1 = df_train.values\n",
    "data2 = df_test.values\n",
    "data3 = df_val.values\n",
    "# alldata = np.concatenate((data1,data2,data3))\n",
    "alldata = data1\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "all_keywords = Counter()\n",
    "count = 0\n",
    "for data in alldata:\n",
    "    data = data[1:]\n",
    "    # keywords = set()\n",
    "    a_keywords = []\n",
    "\n",
    "    for text in data:\n",
    "        text=nltk.word_tokenize(text)\n",
    "        text_list = nltk.pos_tag(text)\n",
    "        # print(text_list)\n",
    "        keywords = []\n",
    "        for word, tag in text_list:\n",
    "            word = word.lower()\n",
    "            if tag.startswith(\"VB\"):\n",
    "                w = lemmatizer.lemmatize(word, pos='v')\n",
    "                if w !='be':\n",
    "                    keywords.append(word)\n",
    "            elif tag.startswith(\"NN\"):\n",
    "                w = lemmatizer.lemmatize(word, pos='n')\n",
    "                keywords.append(word)\n",
    "            else:\n",
    "                continue\n",
    "        tmp = Counter(keywords)\n",
    "        all_keywords += tmp\n",
    "    # print(count)\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "\n",
    "word_freq_dict = {}\n",
    "selected_words = all_keywords.most_common()\n",
    "for w, f in selected_words:\n",
    "    if w[-3:] == 'ing' and w[:-3] in word_list:  # playing\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-3], f)\n",
    "    elif w[-3:] == 'ing' and w[:-4] in word_list:  # running\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-4], f)\n",
    "    elif w[-2:] == 'ly' and w[:-2] in word_list:  # slowly\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-2], f)\n",
    "    elif w[-2:] == 'ly' and w[:-3] in word_list:  # lly\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-3], f)\n",
    "    elif w[-1] == 's' and w[:-1] in word_list:\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-1], f)\n",
    "    elif w[-2:] == 'es' and w[:-2] in word_list:\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-2], f)\n",
    "    elif w[-1] == 'd' and w[:-1] in word_list:\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-1], f)\n",
    "    elif w[-2:] == 'ed' and w[:-2] in word_list:\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-2], f)\n",
    "    elif w[-3:] == 'ing' and w[:-3]+'e' in word_list:\n",
    "        word_freq_dict = dict_add(word_freq_dict, w[:-3]+'e', f)\n",
    "    else:\n",
    "        word_freq_dict = dict_add(word_freq_dict, w, f)\n",
    "\n",
    "word_freq = sorted([(w, f) for w, f in word_freq_dict.items()], key=lambda x: x[1], reverse=True)\n",
    "word_freq = [(w, f) for w, f in word_freq if len(w) > 2]\n",
    "word_list_f = []\n",
    "for w, f in word_freq:\n",
    "    if w not in stop_words:\n",
    "        word_list_f.append((w,f))\n",
    "    else:\n",
    "        print(w)\n",
    "\n",
    "word_list_final = [w for w, f in word_list_f]\n",
    "\n",
    "# TaggingToembs\n",
    "Tag2emb = []\n",
    "for w in word_list_final:\n",
    "    Tag2emb.append(word_list.index(w))\n",
    "# pdb.set_trace()\n",
    "# print(word_list_final, len(word_list_final),word_freq)\n",
    "# pickle.dump(word_list_final, open('word_list_pretrain_rules_train_new.p', 'wb'))\n",
    "# pickle.dump(Tag2emb, open('TaggingToEmbs_train_new.p', 'wb'))\n",
    "# pickle.dump(word_list_final, open('word_list_allwords.p', 'wb'))\n",
    "# pickle.dump(Tag2emb, open('TaggingToEmbs_allwords.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2467"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background\n",
      "someone\n",
      "time\n",
      "play\n",
      "object\n",
      "make\n",
      "distance\n",
      "something\n",
      "start\n",
      "turn\n",
      "get\n",
      "follow\n",
      "come\n",
      "group\n",
      "piece\n",
      "leave\n",
      "begin\n",
      "forth\n",
      "end\n",
      "continue\n",
      "foreground\n",
      "approach\n",
      "rate\n",
      "occur\n",
      "take\n",
      "slow\n",
      "use\n",
      "lot\n",
      "place\n",
      "repeat\n",
      "work\n",
      "item\n",
      "has\n",
      "increase\n",
      "change\n",
      "set\n",
      "page\n",
      "create\n",
      "way\n",
      "have\n",
      "put\n",
      "made\n",
      "night\n",
      "other\n",
      "second\n",
      "note\n",
      "cause\n",
      "pattern\n",
      "variety\n",
      "accelerate\n",
      "overhead\n",
      "become\n",
      "top\n",
      "side\n",
      "day\n",
      "back\n",
      "interval\n",
      "path\n",
      "thing\n",
      "couple\n",
      "signal\n",
      "number\n",
      "system\n",
      "try\n",
      "kind\n",
      "somebody\n",
      "past\n",
      "effect\n",
      "frequency\n",
      "proximity\n",
      "amount\n",
      "cover\n"
     ]
    }
   ],
   "source": [
    "word_freq = sorted([(w, f) for w, f in word_freq_dict.items()], key=lambda x: x[1], reverse=True)\n",
    "word_freq = [(w, f) for w, f in word_freq if len(w) > 2 and f > 5]\n",
    "word_list_f = []\n",
    "for w, f in word_freq:\n",
    "    if w not in stop_words:\n",
    "        word_list_f.append((w,f))\n",
    "    else:\n",
    "        print(w)\n",
    "\n",
    "word_list_final = [w for w, f in word_list_f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = word_list_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_words = word_list_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "count = 0\n",
    "for w in eval_words:\n",
    "    if w in train_words:\n",
    "        indexes.append(train_words.index(w))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a  = torch.tensor(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.where(a<597)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = [(w, f) for w, f in word_freq if len(w) > 2 and f > 11]\n",
    "word_list_f = []\n",
    "for w, f in word_freq:\n",
    "    if w not in stop_words:\n",
    "        word_list_f.append((w,f))\n",
    "    else:\n",
    "        # print(w)\n",
    "        pass\n",
    "\n",
    "word_list_final = [w for w, f in word_list_f][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bird',\n",
       " 'water',\n",
       " 'chirp',\n",
       " 'people',\n",
       " 'person',\n",
       " 'talk',\n",
       " 'car',\n",
       " 'rain',\n",
       " 'run',\n",
       " 'sound',\n",
       " 'wind',\n",
       " 'walk',\n",
       " 'noise',\n",
       " 'move',\n",
       " 'machine',\n",
       " 'pass',\n",
       " 'blow',\n",
       " 'engine',\n",
       " 'drive',\n",
       " 'metal',\n",
       " 'door',\n",
       " 'speak',\n",
       " 'fall',\n",
       " 'vehicle',\n",
       " 'man',\n",
       " 'open',\n",
       " 'train',\n",
       " 'surface',\n",
       " 'sing',\n",
       " 'bell',\n",
       " 'flow',\n",
       " 'traffic',\n",
       " 'hit',\n",
       " 'pour',\n",
       " 'speed',\n",
       " 'ring',\n",
       " 'thunder',\n",
       " 'close',\n",
       " 'dog',\n",
       " 'air',\n",
       " 'hum',\n",
       " 'stop',\n",
       " 'crow',\n",
       " 'pitch',\n",
       " 'buzz',\n",
       " 'splash',\n",
       " 'ground',\n",
       " 'road',\n",
       " 'voice',\n",
       " 'bark',\n",
       " 'motor',\n",
       " 'drip',\n",
       " 'wave',\n",
       " 'tap',\n",
       " 'music',\n",
       " 'paper',\n",
       " 'cricket',\n",
       " 'wood',\n",
       " 'room',\n",
       " 'floor',\n",
       " 'woman',\n",
       " 'container',\n",
       " 'squeak',\n",
       " 'children',\n",
       " 'whistle',\n",
       " 'footsteps',\n",
       " 'rumble',\n",
       " 'stream',\n",
       " 'beep',\n",
       " 'chime',\n",
       " 'pace',\n",
       " 'glass',\n",
       " 'truck',\n",
       " 'radio',\n",
       " 'call',\n",
       " 'roar',\n",
       " 'echo',\n",
       " 'whir',\n",
       " 'rev',\n",
       " 'track',\n",
       " 'street',\n",
       " 'creak',\n",
       " 'machinery',\n",
       " 'roll',\n",
       " 'bang',\n",
       " 'crash',\n",
       " 'rock',\n",
       " 'conversation',\n",
       " 'area',\n",
       " 'rattle',\n",
       " 'fire',\n",
       " 'click',\n",
       " 'faucet',\n",
       " 'cut',\n",
       " 'horn',\n",
       " 'laugh',\n",
       " 'sink',\n",
       " 'roof',\n",
       " 'chat',\n",
       " 'siren',\n",
       " 'scrape',\n",
       " 'instrument',\n",
       " 'station',\n",
       " 'men',\n",
       " 'drain',\n",
       " 'drop',\n",
       " 'pull',\n",
       " 'insect',\n",
       " 'strike',\n",
       " 'fill',\n",
       " 'shut',\n",
       " 'tone',\n",
       " 'storm',\n",
       " 'animal',\n",
       " 'crunch',\n",
       " 'tweet',\n",
       " 'chatter',\n",
       " 'liquid',\n",
       " 'airplane',\n",
       " 'fly',\n",
       " 'wash',\n",
       " 'hand',\n",
       " 'clang',\n",
       " 'crack',\n",
       " 'knock',\n",
       " 'idle',\n",
       " 'shuffle',\n",
       " 'volume',\n",
       " 'clap',\n",
       " 'child',\n",
       " 'dish',\n",
       " 'fade',\n",
       " 'converse',\n",
       " 'clock',\n",
       " 'saw',\n",
       " 'clank',\n",
       " 'motorcycle',\n",
       " 'gravel',\n",
       " 'louder',\n",
       " 'window',\n",
       " 'step',\n",
       " 'type',\n",
       " 'pop',\n",
       " 'break',\n",
       " 'honk',\n",
       " 'ball',\n",
       " 'rush',\n",
       " 'pick',\n",
       " 'drum',\n",
       " 'tune',\n",
       " 'church',\n",
       " 'outdoor',\n",
       " 'river',\n",
       " 'waterfall',\n",
       " 'screech',\n",
       " 'caw',\n",
       " 'shore',\n",
       " 'fan',\n",
       " 'highway',\n",
       " 'table',\n",
       " 'song',\n",
       " 'rustle',\n",
       " 'squawk',\n",
       " 'bubble',\n",
       " 'breath',\n",
       " 'snow',\n",
       " 'flies',\n",
       " 'dropped',\n",
       " 'plane',\n",
       " 'opera',\n",
       " 'pan',\n",
       " 'hammer',\n",
       " 'beat',\n",
       " 'howl',\n",
       " 'women',\n",
       " 'key',\n",
       " 'operate',\n",
       " 'food',\n",
       " 'alarm',\n",
       " 'build',\n",
       " 'heavy',\n",
       " 'shoes',\n",
       " 'shower',\n",
       " 'bottle',\n",
       " 'bus',\n",
       " 'tool',\n",
       " 'cheer',\n",
       " 'space',\n",
       " 'pause',\n",
       " 'tree',\n",
       " 'spray',\n",
       " 'faint',\n",
       " 'coin',\n",
       " 'bounce',\n",
       " 'tick',\n",
       " 'beach',\n",
       " 'spin',\n",
       " 'clink',\n",
       " 'gurgle',\n",
       " 'factory',\n",
       " 'yell',\n",
       " 'travel',\n",
       " 'book',\n",
       " 'pipe',\n",
       " 'bag',\n",
       " 'cough',\n",
       " 'device',\n",
       " 'plastic',\n",
       " 'speaker',\n",
       " 'kid',\n",
       " 'blare',\n",
       " 'cup',\n",
       " 'pound',\n",
       " 'city',\n",
       " 'eat',\n",
       " 'thump',\n",
       " 'gear',\n",
       " 'race',\n",
       " 'write',\n",
       " 'duck',\n",
       " 'ocean',\n",
       " 'announcement',\n",
       " 'scream',\n",
       " 'squeal',\n",
       " 'wheel',\n",
       " 'brake',\n",
       " 'loud',\n",
       " 'grind',\n",
       " 'feet',\n",
       " 'board',\n",
       " 'shout',\n",
       " 'subway',\n",
       " 'push',\n",
       " 'clean',\n",
       " 'resonate',\n",
       " 'sky',\n",
       " 'crackle',\n",
       " 'box',\n",
       " 'vibrate',\n",
       " 'rainfall',\n",
       " 'horse',\n",
       " 'gather',\n",
       " 'tub',\n",
       " 'silence',\n",
       " 'rhythm',\n",
       " 'jet',\n",
       " 'jingle',\n",
       " 'tin',\n",
       " 'ride',\n",
       " 'varying',\n",
       " 'fireworks',\n",
       " 'pool',\n",
       " 'flip',\n",
       " 'plate',\n",
       " 'toilet',\n",
       " 'chair',\n",
       " 'adult',\n",
       " 'pot',\n",
       " 'struck',\n",
       " 'fountain',\n",
       " 'clack',\n",
       " 'shake',\n",
       " 'chant',\n",
       " 'boat',\n",
       " 'house',\n",
       " 'park',\n",
       " 'power',\n",
       " 'stick',\n",
       " 'forest',\n",
       " 'phone',\n",
       " 'emit',\n",
       " 'brush',\n",
       " 'dragged',\n",
       " 'seagull',\n",
       " 'frog',\n",
       " 'release',\n",
       " 'produce',\n",
       " 'clatter',\n",
       " 'accompanied',\n",
       " 'pavement',\n",
       " 'bunch',\n",
       " 'helicopter',\n",
       " 'gun',\n",
       " 'bug',\n",
       " 'rub',\n",
       " 'grow',\n",
       " 'light',\n",
       " 'movement',\n",
       " 'flush',\n",
       " 'intensity',\n",
       " 'bucket',\n",
       " 'gutter',\n",
       " 'bee',\n",
       " 'drill',\n",
       " 'burn',\n",
       " 'whine',\n",
       " 'cat',\n",
       " 'sheet',\n",
       " 'trickle',\n",
       " 'grass',\n",
       " 'hall',\n",
       " 'creek',\n",
       " 'cow',\n",
       " 'drone',\n",
       " 'melody',\n",
       " 'synthesizer',\n",
       " 'stairs',\n",
       " 'restaurant',\n",
       " 'steam',\n",
       " 'keep',\n",
       " 'print',\n",
       " 'scratch',\n",
       " 'baby',\n",
       " 'revved',\n",
       " 'gust',\n",
       " 'hiss',\n",
       " 'hinge',\n",
       " 'thud',\n",
       " 'garage',\n",
       " 'knife',\n",
       " 'brief',\n",
       " 'quack',\n",
       " 'swing',\n",
       " 'television',\n",
       " 'dryer',\n",
       " 'material',\n",
       " 'bit',\n",
       " 'cloth',\n",
       " 'muffled',\n",
       " 'environment',\n",
       " 'pile',\n",
       " 'boom',\n",
       " 'coffee',\n",
       " 'emergency',\n",
       " 'kitchen',\n",
       " 'thunderstorm',\n",
       " 'while',\n",
       " 'breeze',\n",
       " 'switch',\n",
       " 'sort',\n",
       " 'join',\n",
       " 'nature',\n",
       " 'basin',\n",
       " 'tunnel',\n",
       " 'force',\n",
       " 'hear',\n",
       " 'chip',\n",
       " 'growl',\n",
       " 'dragging',\n",
       " 'construction',\n",
       " 'gate',\n",
       " 'chain',\n",
       " 'chop',\n",
       " 'drawer',\n",
       " 'sit',\n",
       " 'slosh',\n",
       " 'shift',\n",
       " 'lawn',\n",
       " 'silverware',\n",
       " 'gas',\n",
       " 'game',\n",
       " 'sidewalk',\n",
       " 'fashion',\n",
       " 'spoon',\n",
       " 'cook',\n",
       " 'land',\n",
       " 'ice',\n",
       " 'equipment',\n",
       " 'twigs',\n",
       " 'species',\n",
       " 'vacuum',\n",
       " 'hail',\n",
       " 'cry',\n",
       " 'croak',\n",
       " 'puddle',\n",
       " 'sharpen',\n",
       " 'ding',\n",
       " 'bleat',\n",
       " 'let',\n",
       " 'frying',\n",
       " 'pressure',\n",
       " 'outside',\n",
       " 'boots',\n",
       " 'wall',\n",
       " 'lock',\n",
       " 'perform',\n",
       " 'load',\n",
       " 'including',\n",
       " 'sea',\n",
       " 'intercom',\n",
       " 'lid',\n",
       " 'flap',\n",
       " 'communicate',\n",
       " 'generate',\n",
       " 'reverberate',\n",
       " 'rise',\n",
       " 'boil',\n",
       " 'video',\n",
       " 'whooshing',\n",
       " 'jar',\n",
       " 'automobile',\n",
       " 'chug',\n",
       " 'drown',\n",
       " 'tapped',\n",
       " 'motion',\n",
       " 'pond',\n",
       " 'rooster',\n",
       " 'swim',\n",
       " 'sizzle',\n",
       " 'chicken',\n",
       " 'sand',\n",
       " 'give',\n",
       " 'stopped',\n",
       " 'printer',\n",
       " 'broken',\n",
       " 'shaken',\n",
       " 'feedback',\n",
       " 'dirt',\n",
       " 'point',\n",
       " 'line',\n",
       " 'slide',\n",
       " 'finger',\n",
       " 'throw',\n",
       " 'stack',\n",
       " 'hoot',\n",
       " 'mill',\n",
       " 'file',\n",
       " 'body',\n",
       " 'rainstorm',\n",
       " 'medium',\n",
       " 'zipper',\n",
       " 'rubbed',\n",
       " 'flock',\n",
       " 'utensil',\n",
       " 'cross',\n",
       " 'indoor',\n",
       " 'vibration',\n",
       " 'drink',\n",
       " 'passenger',\n",
       " 'rail',\n",
       " 'string',\n",
       " 'part',\n",
       " 'lap',\n",
       " 'whisper',\n",
       " 'murmur',\n",
       " 'wearing',\n",
       " 'middle',\n",
       " 'heels',\n",
       " 'railroad',\n",
       " 'bowl',\n",
       " 'belt',\n",
       " 'clip',\n",
       " 'sweep',\n",
       " 'blast',\n",
       " 'zoom',\n",
       " 'hallway',\n",
       " 'keyboard',\n",
       " 'toy',\n",
       " 'microwave',\n",
       " 'bath',\n",
       " 'wiper',\n",
       " 'warn',\n",
       " 'stand',\n",
       " 'moo',\n",
       " 'press',\n",
       " 'thrown',\n",
       " 'playground',\n",
       " 'elevator',\n",
       " 'police',\n",
       " 'windshield',\n",
       " 'operation',\n",
       " 'stone',\n",
       " 'slam',\n",
       " 'worker',\n",
       " 'coo',\n",
       " 'clear',\n",
       " 'shovel',\n",
       " 'gush',\n",
       " 'mix',\n",
       " 'field',\n",
       " 'mouth',\n",
       " 'blown',\n",
       " 'manner',\n",
       " 'stove',\n",
       " 'static',\n",
       " 'market',\n",
       " 'raindrop',\n",
       " 'pencil',\n",
       " 'oil',\n",
       " 'tire',\n",
       " 'patter',\n",
       " 'burst',\n",
       " 'flipped',\n",
       " 'band',\n",
       " 'event',\n",
       " 'porch',\n",
       " 'cart',\n",
       " 'shot',\n",
       " 'cycle',\n",
       " 'lead']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ca450b71c8cd6d3607fcf78bd9dddd00baa1537e5df95d3e52a8d8431cf7133"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
